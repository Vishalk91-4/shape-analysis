{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"HmpyE3PpWAgI\"\n",
    "      },\n",
    "      \"source\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ZP3NjApxVOVC\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# 00 Inital Steps\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"kQUEh4F5NXbx\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"!pip install keras-unet-collection\\n\",\n",
    "        \"!pip install -U -q segmentation-models\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 2,\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"dSCGeR5sp0AU\",\n",
    "        \"outputId\": \"85504919-15e9-4e26-ade5-5ea3d560c53b\"\n",
    "      },\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"name\": \"stdout\",\n",
    "          \"output_type\": \"stream\",\n",
    "          \"text\": [\n",
    "            \"Segmentation Models: using `tf.keras` framework.\\n\"\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"source\": [\n",
    "        \"import os\\n\",\n",
    "        \"os.environ[\\\"SM_FRAMEWORK\\\"] = \\\"tf.keras\\\"\\n\",\n",
    "        \"import cv2\\n\",\n",
    "        \"import json\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"from glob import glob\\n\",\n",
    "        \"from google.colab import drive\\n\",\n",
    "        \"from keras import backend as K\\n\",\n",
    "        \"from keras.metrics import Precision, Recall, AUC, Accuracy\\n\",\n",
    "        \"from keras_unet_collection import losses, models, utils\\n\",\n",
    "        \"import segmentation_models as sm\\n\",\n",
    "        \"from skimage import measure\\n\",\n",
    "        \"from sklearn.utils import shuffle\\n\",\n",
    "        \"from tensorflow import keras\\n\",\n",
    "        \"from tensorflow.keras.callbacks import EarlyStopping\\n\",\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from pycocotools import mask\\n\",\n",
    "        \"from pycocotools.coco import COCO\\n\",\n",
    "        \"from pycocotools.cocoeval import COCOeval\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Mbq5qvrAp0AZ\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### some functions for later\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 3,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"dRiJIhtVp0AZ\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"%matplotlib inline\\n\",\n",
    "        \"def ax_decorate_box(ax):\\n\",\n",
    "        \"    [j.set_linewidth(0) for j in ax.spines.values()]\\n\",\n",
    "        \"    ax.tick_params(axis=\\\"both\\\", which=\\\"both\\\", bottom=False, top=False, \\\\\\n\",\n",
    "        \"               labelbottom=False, left=False, right=False, labelleft=False)\\n\",\n",
    "        \"    return ax\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 4,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ilf4mScLAJD4\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Plotting function\\n\",\n",
    "        \"def plot_metrics(history, metrics_list):\\n\",\n",
    "        \"    for metric in metrics_list:\\n\",\n",
    "        \"        plt.figure()\\n\",\n",
    "        \"\\n\",\n",
    "        \"        metric_values = history.history[metric]\\n\",\n",
    "        \"        val_metric_values = history.history['val_'+metric]\\n\",\n",
    "        \"\\n\",\n",
    "        \"        epochs = range(1, len(metric_values) + 1)\\n\",\n",
    "        \"        plt.plot(epochs, metric_values, 'y', label='Training '+metric)\\n\",\n",
    "        \"        plt.plot(epochs, val_metric_values, 'r', label='Validation '+metric)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        plt.title('Training and Validation '+metric)\\n\",\n",
    "        \"        plt.xlabel('Epochs')\\n\",\n",
    "        \"        plt.ylabel(metric)\\n\",\n",
    "        \"        plt.legend()\\n\",\n",
    "        \"        plt.savefig(metric+'_plot.jpg')\\n\",\n",
    "        \"        plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 5,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"9QUdlxu_CSqq\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def make_coco_eval_data(image_directory,mask_directory,change_diff):\\n\",\n",
    "        \"    annotations = []\\n\",\n",
    "        \"    images = []\\n\",\n",
    "        \"    for i, image_name in enumerate(os.listdir(image_directory)):\\n\",\n",
    "        \"        image = cv2.imread(os.path.join(image_directory, image_name))\\n\",\n",
    "        \"\\n\",\n",
    "        \"        images.append({\\n\",\n",
    "        \"            \\\"id\\\": i,\\n\",\n",
    "        \"            \\\"file_name\\\": image_name,\\n\",\n",
    "        \"            \\\"width\\\": image.shape[1],\\n\",\n",
    "        \"            \\\"height\\\": image.shape[0],\\n\",\n",
    "        \"        })\\n\",\n",
    "        \"\\n\",\n",
    "        \"        mask = cv2.imread(os.path.join(mask_directory, image_name.replace('.jpg', change_diff)), cv2.IMREAD_GRAYSCALE)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        for class_id in range(0, 10):  # Assuming class IDs start from 1\\n\",\n",
    "        \"            binary_mask = (mask == class_id).astype(np.uint8)\\n\",\n",
    "        \"            area = np.sum(binary_mask)\\n\",\n",
    "        \"\\n\",\n",
    "        \"            contours = measure.find_contours(binary_mask, 0.5)\\n\",\n",
    "        \"\\n\",\n",
    "        \"            segmentation = []\\n\",\n",
    "        \"            area = 0\\n\",\n",
    "        \"            for contour in contours:\\n\",\n",
    "        \"                contour = np.flip(contour, axis=1)\\n\",\n",
    "        \"                seg = contour.ravel().tolist()\\n\",\n",
    "        \"                # area += cv2.contourArea(contour)\\n\",\n",
    "        \"                if len(seg) > 4:\\n\",\n",
    "        \"                    segmentation.append(seg)\\n\",\n",
    "        \"            if len(segmentation) == 0:\\n\",\n",
    "        \"                continue\\n\",\n",
    "        \"            # area = cv2.contourArea(contour)\\n\",\n",
    "        \"\\n\",\n",
    "        \"            annotations.append({\\n\",\n",
    "        \"                \\\"id\\\": len(annotations) + 1,\\n\",\n",
    "        \"                \\\"image_id\\\": i,\\n\",\n",
    "        \"                \\\"category_id\\\": class_id,\\n\",\n",
    "        \"                \\\"width\\\": image.shape[1],\\n\",\n",
    "        \"                \\\"height\\\": image.shape[0],\\n\",\n",
    "        \"                \\\"score\\\": 0.0,\\n\",\n",
    "        \"                \\\"bbox\\\": [float(np.min(contour[:, 0])), float(np.min(contour[:, 1])),\\n\",\n",
    "        \"                        float(np.max(contour[:, 0]) - np.min(contour[:, 0])),\\n\",\n",
    "        \"                        float(np.max(contour[:, 1]) - np.min(contour[:, 1]))],\\n\",\n",
    "        \"                \\\"area\\\": area,#300,#float(maskUtils.area(maskUtils.encode(np.asfortranarray(binary_mask)))),\\n\",\n",
    "        \"                \\\"segmentation\\\": segmentation,\\n\",\n",
    "        \"                \\\"iscrowd\\\": 0,\\n\",\n",
    "        \"            })\\n\",\n",
    "        \"    return images, annotations\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"UgaDCoZgCBr0\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# 01 Preprocessing\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"trPSMAIbBCaD\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"drive.mount('/content/gdrive/', force_remount=True)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 22,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ZCIfKsh3wTuf\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"!unzip 10S_raw_abt.zip\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 6,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"pRhdirfJAcf6\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"img_SIZE = 256\\n\",\n",
    "        \"num_CLASSES = 11\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"jfhsGvPfAsHX\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### Basic Normalisation\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 7,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nufkOKKjAoxb\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def input_data_process(input_array):\\n\",\n",
    "        \"    '''converting pixel vales to [0, 1]'''\\n\",\n",
    "        \"    return input_array/255.\\n\",\n",
    "        \"\\n\",\n",
    "        \"def target_data_process(target_array):\\n\",\n",
    "        \"    return keras.utils.to_categorical(target_array, num_classes=num_CLASSES)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"_JUkuavUXJes\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Uncomment this one if you want to use it with the 5S dataset.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 14,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Ao_6u2gWBVka\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# ## this one is for our 5 Shape dataset where some of the particles class lables\\n\",\n",
    "        \"# ## need to be remapped\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"# def input_data_process(input_array):\\n\",\n",
    "        \"#     '''converting pixel vales to [0, 1]'''\\n\",\n",
    "        \"#     return input_array/255\\n\",\n",
    "        \"\\n\",\n",
    "        \"# def target_data_process(target_array):\\n\",\n",
    "        \"#     target_array[target_array == 8] = 4\\n\",\n",
    "        \"#     target_array[target_array == 9] = 5\\n\",\n",
    "        \"#     return keras.utils.to_categorical(target_array, num_classes=num_CLASSES)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"GQJFN1UOAzw4\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### Keras VGG16 Normalisation\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"uh1PwhSFBFLn\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# def input_data_process(input_array):\\n\",\n",
    "        \"#     return tf.keras.applications.vgg16.preprocess_input(input_array, data_format=None)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# def target_data_process(target_array):\\n\",\n",
    "        \"#     return keras.utils.to_categorical(target_array, num_classes=num_CLASSES)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"3fEKAuciAXCn\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# def input_data_process_vis(input_array):\\n\",\n",
    "        \"#     '''converting pixel vales to [0, 1]'''\\n\",\n",
    "        \"#     return input_array/255\\n\",\n",
    "        \"\\n\",\n",
    "        \"# def target_data_process_vis(target_array):\\n\",\n",
    "        \"#     return keras.utils.to_categorical(target_array, num_classes=num_CLASSES)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"I1NWkRpn-uRN\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"### load images\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"W848n6qwX2ML\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"dataset_mode = 'abt' # change abt to raw if you want to train on only the raw data\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"TwBlFOawIu1k\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# paths to your dataset\\n\",\n",
    "        \"path_train_img_raw = '/content/img_train/'\\n\",\n",
    "        \"path_train_mask_raw = '/content/msk_train/'\\n\",\n",
    "        \"path_train_img_a = '/content/iabt_img_train/'\\n\",\n",
    "        \"path_train_mask_a = '/content/iabt_msk_train/'\\n\",\n",
    "        \"\\n\",\n",
    "        \"path_valid_img = '/content/img_val/'\\n\",\n",
    "        \"path_valid_mask = '/content/msk_val/'\\n\",\n",
    "        \"\\n\",\n",
    "        \"path_test_img = '/content/img_test/'\\n\",\n",
    "        \"path_test_mask = '/content/msk_test/'\\n\",\n",
    "        \"\\n\",\n",
    "        \"train_input_names_raw = np.array(sorted(glob(path_train_img_raw +'*.jpg')))\\n\",\n",
    "        \"train_label_names_raw = np.array(sorted(glob(path_train_mask_raw +'*.png')))\\n\",\n",
    "        \"\\n\",\n",
    "        \"train_input_names_a = np.array(sorted(glob(path_train_img_a +'*.jpg')))\\n\",\n",
    "        \"train_label_names_a = np.array(sorted(glob(path_train_mask_a +'*.png')))\\n\",\n",
    "        \"\\n\",\n",
    "        \"if dataset_mode == 'raw':\\n\",\n",
    "        \"  train_input_names_a = np.array(sorted(glob(path_train_img_raw +'*.jpg')))\\n\",\n",
    "        \"  train_label_names_a = np.array(sorted(glob(path_train_mask_raw +'*.png')))\\n\",\n",
    "        \"\\n\",\n",
    "        \"train_input_names = np.concatenate((train_input_names_raw,\\n\",\n",
    "        \"                                    train_input_names_a),\\n\",\n",
    "        \"                                   axis=0)\\n\",\n",
    "        \"train_label_names = np.concatenate((train_label_names_raw,\\n\",\n",
    "        \"                                    train_label_names_a),\\n\",\n",
    "        \"                                   axis=0)\\n\",\n",
    "        \"\\n\",\n",
    "        \"valid_input_names = np.array(sorted(glob(path_valid_img +'*.jpg')))\\n\",\n",
    "        \"valid_label_names = np.array(sorted(glob(path_valid_mask +'*.png')))\\n\",\n",
    "        \"test_input_names = np.array(sorted(glob(path_test_img+'*.jpg')))\\n\",\n",
    "        \"test_label_names = np.array(sorted(glob(path_test_mask+'*.png')))\\n\",\n",
    "        \"L_train = len(train_input_names)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Training:validation = {}:{}:{}\\\".format(len(train_input_names),\\n\",\n",
    "        \"                                              len(valid_input_names),\\n\",\n",
    "        \"                                              len(test_label_names)))\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": 20,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"3WM91JHNiS7E\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"a_shuffled, b_shuffled = shuffle(train_input_names, train_label_names)\\n\",\n",
    "        \"### SHUFFLE\\n\",\n",
    "        \"train_input = input_data_process(utils.image_to_array(a_shuffled,\\n\",\n",
    "        \"                                                      size=img_SIZE,\\n\",\n",
    "        \"                                                      channel=3))\\n\",\n",
    "        \"train_label = target_data_process(utils.image_to_array(b_shuffled,\\n\",\n",
    "        \"                                                       size=img_SIZE,\\n\",\n",
    "        \"                                                       channel=1))\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Uq3pS926p0Ab\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"valid_input = input_data_process(utils.image_to_array(valid_input_names,\\n\",\n",
    "        \"                                                      size=img_SIZE,\\n\",\n",
    "        \"                                                      channel=3))\\n\",\n",
    "        \"valid_label = target_data_process(utils.image_to_array(valid_label_names,\\n\",\n",
    "        \"                                                       size=img_SIZE,\\n\",\n",
    "        \"                                                       channel=1))\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Q97uRXoF-0wZ\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### visualise some of the training data\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"eXlLPDdMRCp8\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_random_images(input_images, label_images, num_images):\\n\",\n",
    "        \"    indices = np.random.choice(len(input_images), num_images)\\n\",\n",
    "        \"    for idx in indices:\\n\",\n",
    "        \"        label_class = np.argmax(train_label[idx], axis=-1)\\n\",\n",
    "        \"        plt.figure(figsize=(10,5))\\n\",\n",
    "        \"        plt.subplot(1, 2, 1)\\n\",\n",
    "        \"        plt.imshow(train_input[idx])\\n\",\n",
    "        \"        plt.title('Input Image')\\n\",\n",
    "        \"        plt.subplot(1, 2, 2)\\n\",\n",
    "        \"        plt.imshow(label_class, cmap='gray')\\n\",\n",
    "        \"        plt.title('Label')\\n\",\n",
    "        \"        plt.show()\\n\",\n",
    "        \"        unique_classes = np.unique(label_class)\\n\",\n",
    "        \"        print(f\\\"Unique classes represented in the label image: {unique_classes}\\\")\\n\",\n",
    "        \"plot_random_images(train_input_names, train_label_names, num_images=10)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"k06nxxYOwxg4\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### calc weights for imbalance\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"RjuxCIx1Ey2r\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import numpy as np\\n\",\n",
    "        \"\\n\",\n",
    "        \"num_classes = train_label.shape[-1]\\n\",\n",
    "        \"class_counts = np.sum(train_label, axis=(0,1,2))\\n\",\n",
    "        \"print('Pixel per class:')\\n\",\n",
    "        \"print(class_counts)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Calculate class weights\\n\",\n",
    "        \"class_weights = 1. / class_counts  # Inverse of the number of pixels\\n\",\n",
    "        \"class_weights = class_weights / np.max(class_weights)\\n\",\n",
    "        \"print('Class weights for Dice Loss')\\n\",\n",
    "        \"print(class_weights)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"9UUpk70e2qIX\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# 02 Model selection\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"cCT0KDY__-rW\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"## unet\\n\",\n",
    "        \"model = models.unet_2d((img_SIZE, img_SIZE, 3), filter_num=[64, 128, 256, 512, 1024], n_labels=num_CLASSES, stack_num_down=2, stack_num_up=2,\\n\",\n",
    "        \"            activation='ReLU', output_activation='Softmax', batch_norm=False, pool=True, unpool=True,\\n\",\n",
    "        \"            backbone='VGG16', weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='unet')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"hA9eRRqZ2uMq\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"## attent UNet\\n\",\n",
    "        \"model = models.att_unet_2d((img_SIZE, img_SIZE, 3), filter_num=[64, 128, 256, 512, 1024], n_labels=num_CLASSES,\\n\",\n",
    "        \"                           stack_num_down=2, stack_num_up=2, activation='ReLU',\\n\",\n",
    "        \"                           atten_activation='ReLU', attention='add', output_activation='Softmax',\\n\",\n",
    "        \"                           batch_norm=False, pool=True, unpool=True,\\n\",\n",
    "        \"                           backbone='VGG16', weights='imagenet',\\n\",\n",
    "        \"                           freeze_backbone=True, freeze_batch_norm=True,\\n\",\n",
    "        \"                           name='attunet')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"REMZnPkJ20Ym\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"## UNet+++\\n\",\n",
    "        \"model = models.unet_3plus_2d((img_SIZE, img_SIZE, 3), n_labels=num_CLASSES, filter_num_down=[64, 128, 256, 512, 1024], filter_num_skip='auto', filter_num_aggregate='auto',\\n\",\n",
    "        \"                  stack_num_down=2, stack_num_up=2, activation='ReLU', output_activation='Softmax',\\n\",\n",
    "        \"                  batch_norm=False, pool=True, unpool=True, deep_supervision=False,\\n\",\n",
    "        \"                  backbone='VGG16', weights='imagenet', freeze_backbone=True, freeze_batch_norm=True, name='unet3plus')\\n\",\n",
    "        \"\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"VtMD5w8mYVm2\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### compile the model\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"WnRtmvuw9c23\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"dice_loss = sm.losses.DiceLoss(class_weights=class_weights)\\n\",\n",
    "        \"total_loss = dice_loss\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"wRYTfD6o9vvs\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"metrics = [\\n\",\n",
    "        \"    sm.metrics.IOUScore(threshold=0.5)\\n\",\n",
    "        \"    ]\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XgnRs7UJATFz\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"model.compile(loss=total_loss,\\n\",\n",
    "        \"              optimizer=keras.optimizers.Adam(learning_rate=0.00025),\\n\",\n",
    "        \"              metrics=metrics)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"dPhoFOF9b2p6\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# 03 Train\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"eePnjtyGbzPA\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"N_epoch = 64\\n\",\n",
    "        \"N_batch = 8\\n\",\n",
    "        \"\\n\",\n",
    "        \"model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\\n\",\n",
    "        \"    filepath='/content/tmp1/',\\n\",\n",
    "        \"    save_weights_only=True,\\n\",\n",
    "        \"    monitor='val_iou_score',\\n\",\n",
    "        \"    mode='max',\\n\",\n",
    "        \"    save_best_only=True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Train your model\\n\",\n",
    "        \"history1 = model.fit(\\n\",\n",
    "        \"    x=train_input,\\n\",\n",
    "        \"    y=train_label,\\n\",\n",
    "        \"    batch_size=N_batch,\\n\",\n",
    "        \"    epochs=N_epoch,\\n\",\n",
    "        \"    shuffle=True,\\n\",\n",
    "        \"    validation_data=(valid_input, valid_label),\\n\",\n",
    "        \"    callbacks=[model_checkpoint_callback])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# load the best performing model\\n\",\n",
    "        \"model.load_weights('/content/tmp1/')\\n\",\n",
    "        \"y_pred = model.predict(valid_input)\\n\",\n",
    "        \"val_iou = np.mean(losses.iou_seg(valid_label, y_pred))\\n\",\n",
    "        \"iou_per_class = []\\n\",\n",
    "        \"for i in range(num_CLASSES):\\n\",\n",
    "        \"    iou = np.mean(losses.iou_seg(valid_label[..., i], y_pred[..., i]))\\n\",\n",
    "        \"    iou_per_class.append(iou)\\n\",\n",
    "        \"print('IoU loss per class:', iou_per_class)\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"########## only raw\\n\",\n",
    "        \"train_input = input_data_process(utils.image_to_array(\\n\",\n",
    "        \"                                                    train_input_names_raw,\\n\",\n",
    "        \"                                                    size=img_SIZE, channel=3))\\n\",\n",
    "        \"train_label = target_data_process(utils.image_to_array(\\n\",\n",
    "        \"                                                    train_label_names_raw,\\n\",\n",
    "        \"                                                    size=img_SIZE, channel=1))\\n\",\n",
    "        \"\\n\",\n",
    "        \"model.load_weights('/content/tmp1/')\\n\",\n",
    "        \"K.set_value(model.optimizer.learning_rate, 0.000025)\\n\",\n",
    "        \"N_epoch = 32\\n\",\n",
    "        \"N_batch = 8\\n\",\n",
    "        \"\\n\",\n",
    "        \"model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\\n\",\n",
    "        \"    filepath='/content/tmp/',\\n\",\n",
    "        \"    save_weights_only=True,\\n\",\n",
    "        \"    monitor='val_iou_score',\\n\",\n",
    "        \"    mode='max',\\n\",\n",
    "        \"    save_best_only=True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Train your model\\n\",\n",
    "        \"history2 = model.fit(\\n\",\n",
    "        \"    x=train_input,\\n\",\n",
    "        \"    y=train_label,\\n\",\n",
    "        \"    batch_size=N_batch,\\n\",\n",
    "        \"    epochs=N_epoch,\\n\",\n",
    "        \"    shuffle=True,\\n\",\n",
    "        \"    validation_data=(valid_input, valid_label),\\n\",\n",
    "        \"    callbacks=[model_checkpoint_callback])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# load the best performing model\\n\",\n",
    "        \"model.load_weights('/content/tmp/')\\n\",\n",
    "        \"y_pred = model.predict(valid_input)\\n\",\n",
    "        \"val_iou = np.mean(losses.iou_seg(valid_label, y_pred))\\n\",\n",
    "        \"iou_per_class = []\\n\",\n",
    "        \"for i in range(num_CLASSES):\\n\",\n",
    "        \"    iou = np.mean(losses.iou_seg(valid_label[..., i], y_pred[..., i]))\\n\",\n",
    "        \"    iou_per_class.append(iou)\\n\",\n",
    "        \"print('IoU loss per class:', iou_per_class)\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"#########################################\\n\",\n",
    "        \"model.load_weights('/content/tmp/')\\n\",\n",
    "        \"K.set_value(model.optimizer.learning_rate, 0.0000025)\\n\",\n",
    "        \"N_epoch = 16\\n\",\n",
    "        \"N_batch = 8\\n\",\n",
    "        \"\\n\",\n",
    "        \"model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\\n\",\n",
    "        \"    filepath='/content/tmp/',\\n\",\n",
    "        \"    save_weights_only=True,\\n\",\n",
    "        \"    monitor='val_iou_score',\\n\",\n",
    "        \"    mode='max',\\n\",\n",
    "        \"    save_best_only=True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Train your model\\n\",\n",
    "        \"history3 = model.fit(\\n\",\n",
    "        \"    x=train_input,\\n\",\n",
    "        \"    y=train_label,\\n\",\n",
    "        \"    batch_size=N_batch,\\n\",\n",
    "        \"    epochs=N_epoch,\\n\",\n",
    "        \"    shuffle=True,\\n\",\n",
    "        \"    validation_data=(valid_input, valid_label),\\n\",\n",
    "        \"    callbacks=[model_checkpoint_callback])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# load the best performing model\\n\",\n",
    "        \"model.load_weights('/content/tmp/')\\n\",\n",
    "        \"y_pred = model.predict(valid_input)\\n\",\n",
    "        \"val_iou = np.mean(losses.iou_seg(valid_label, y_pred))\\n\",\n",
    "        \"iou_per_class = []\\n\",\n",
    "        \"for i in range(num_CLASSES):\\n\",\n",
    "        \"    iou = np.mean(losses.iou_seg(valid_label[..., i], y_pred[..., i]))\\n\",\n",
    "        \"    iou_per_class.append(iou)\\n\",\n",
    "        \"print('IoU loss per class:', iou_per_class)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"HABcbfojnMkW\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plot_metrics(history1, metrics_list=['loss', 'iou_score'])\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"yy5vB7TaPFgi\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plot_metrics(history2, metrics_list=['loss', 'iou_score'])\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"px7-LfQhPFRU\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plot_metrics(history3, metrics_list=['loss', 'iou_score'])\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"h6iGWIKxc7KT\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# 04 Evaluate\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Wby401vVon9B\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"test_metrics = model.evaluate(x=test_input, y=test_label, batch_size=N_batch)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\nEvaluation results:\\\")\\n\",\n",
    "        \"for name, value in zip(model.metrics_names, test_metrics):\\n\",\n",
    "        \"    print(f\\\"{name}: {value}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"MOLBMPoWgyZg\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"y_pred = model.predict(test_input)\\n\",\n",
    "        \"val_iou = np.mean(losses.iou_seg(test_label, y_pred))\\n\",\n",
    "        \"iou_per_class = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"for i in range(num_CLASSES):\\n\",\n",
    "        \"    iou = np.mean(losses.iou_seg(test_label[..., i], y_pred[..., i]))\\n\",\n",
    "        \"    iou_per_class.append(iou)\\n\",\n",
    "        \"print('IoU loss per class test:', iou_per_class)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"bgAUbg_1DJFA\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"# Predict the segmentation for this sample\\n\",\n",
    "        \"prediction = y_pred\\n\",\n",
    "        \"# test_input_vis = input_data_process_vis(utils.image_to_array(test_input_names, size=img_SIZE, channel=3))\\n\",\n",
    "        \"for i in range(len(test_input)):\\n\",\n",
    "        \"  # Convert the prediction to a single-channel segmentation mask\\n\",\n",
    "        \"  pred_mask = np.argmax(prediction[i], axis=-1)\\n\",\n",
    "        \"  # Convert the ground truth to a single-channel segmentation mask\\n\",\n",
    "        \"  gt_mask = np.argmax(test_label[i], axis=-1)\\n\",\n",
    "        \"  plt.imsave('results/'+str(i) +'_.jpg',test_input[i])\\n\",\n",
    "        \"  cv2.imwrite('results/'+str(i) +'_dt.png', pred_mask)\\n\",\n",
    "        \"  cv2.imwrite('results/'+str(i) +'_gt.png', gt_mask)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"p1y_0OcnZUZU\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"Use this one if you are using VGG normalisation.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"lFSmQbTwpNyy\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"### use this one if you are using VGG normalization\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"# # Predict the segmentation for this sample\\n\",\n",
    "        \"# prediction = model.predict(test_input)\\n\",\n",
    "        \"# test_input_vis = input_data_process_vis(utils.image_to_array(test_input_names, size=img_SIZE, channel=3))\\n\",\n",
    "        \"# for i in range(len(test_input_vis)):\\n\",\n",
    "        \"#   # Convert the prediction to a single-channel segmentation mask\\n\",\n",
    "        \"#   pred_mask = np.argmax(prediction[i], axis=-1)\\n\",\n",
    "        \"#   # Convert the ground truth to a single-channel segmentation mask\\n\",\n",
    "        \"#   gt_mask = np.argmax(test_label[i], axis=-1)\\n\",\n",
    "        \"#   plt.imsave('results/'+str(i) +'_.jpg',test_input_vis[i])\\n\",\n",
    "        \"#   cv2.imwrite('results/'+str(i) +'_dt.png', pred_mask) #pred_mask\\n\",\n",
    "        \"#   cv2.imwrite('results/'+str(i) +'_gt.png', gt_mask) #pred_mask\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"6q39YcklZYaS\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"### preparing for MS-COCO evaluatio\\n\",\n",
    "        \"since the coco library needs a specific format in order to evaluate\\n\",\n",
    "        \"this is a \\\"poor mans implementation\\\" for doing so.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"fF3HUV6Ie6Wd\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"image_directory_GT = 'results'\\n\",\n",
    "        \"mask_directory_GT = 'results'\\n\",\n",
    "        \"output_file_GT = 'GT_anno.json'\\n\",\n",
    "        \"change_diff_GT = 'gt.png'\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"image_directory_DT = 'results'\\n\",\n",
    "        \"mask_directory_DT = 'results'\\n\",\n",
    "        \"output_file_DT = 'results_GT_anno.json'\\n\",\n",
    "        \"change_diff_DT = 'dt.png'\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Save everything to the annotation file\\n\",\n",
    "        \"images, annotations = make_coco_eval_data(image_directory_GT,mask_directory_GT,change_diff_GT)\\n\",\n",
    "        \"with open(output_file_GT, 'w') as f:\\n\",\n",
    "        \"    json.dump({\\n\",\n",
    "        \"        \\\"images\\\": images,\\n\",\n",
    "        \"        \\\"annotations\\\": annotations,\\n\",\n",
    "        \"        \\\"categories\\\": [{\\\"id\\\": i, \\\"name\\\": str(i)} for i in range(0, 10)],\\n\",\n",
    "        \"    }, f)\\n\",\n",
    "        \"images, annotations2 = make_coco_eval_data(image_directory_DT,mask_directory_DT,change_diff_DT)\\n\",\n",
    "        \"with open(output_file_DT, 'w') as f:\\n\",\n",
    "        \"    json.dump({\\\"annotations\\\":annotations2\\n\",\n",
    "        \"    }, f)\\n\",\n",
    "        \"with open('/content/results_GT_anno.json', 'r') as f:\\n\",\n",
    "        \"    data = f.read()\\n\",\n",
    "        \"    tmp = data[16:-1]\\n\",\n",
    "        \"\\n\",\n",
    "        \"with open('new_results_GT_anno.json', 'w') as f:\\n\",\n",
    "        \"    f.write(tmp)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"eanitDcadOVi\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"cocoGt=COCO('/content/GT_anno.json')\\n\",\n",
    "        \"cocoDt=cocoGt.loadRes('/content/new_results_GT_anno.json')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"qTj41Z3XdOOf\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"cocoEval = COCOeval(cocoGt,cocoDt,'segm')\\n\",\n",
    "        \"# cocoEval.params.imgIds  = 1\\n\",\n",
    "        \"cocoEval.evaluate()\\n\",\n",
    "        \"cocoEval.accumulate()\\n\",\n",
    "        \"cocoEval.summarize()\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"accelerator\": \"GPU\",\n",
    "    \"colab\": {\n",
    "      \"collapsed_sections\": [\n",
    "        \"VDjeb6uuZp_u\",\n",
    "        \"Mbq5qvrAp0AZ\",\n",
    "        \"UgaDCoZgCBr0\",\n",
    "        \"jfhsGvPfAsHX\",\n",
    "        \"GQJFN1UOAzw4\",\n",
    "        \"eFcr5_WPIwGQ\",\n",
    "        \"I1NWkRpn-uRN\",\n",
    "        \"Q97uRXoF-0wZ\",\n",
    "        \"k06nxxYOwxg4\",\n",
    "        \"9UUpk70e2qIX\",\n",
    "        \"VtMD5w8mYVm2\",\n",
    "        \"dPhoFOF9b2p6\",\n",
    "        \"h6iGWIKxc7KT\"\n",
    "      ],\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.6.8\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
